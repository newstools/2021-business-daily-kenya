Artificial intelligence (AI) is the simulation of human intelligence by computer systems. These systems are able to think and act like human beings and make decisions. AI is on the rise globally and almost every sector applies some form of it. In the legal sector, for instance, there are a few robot lawyers that are able to provide legal advice on simple matters. An app known as DoNotPay is reputed to be the world’s first robot lawyer and is used in drafting letters and other simple documents. How does it works? You tell the robot lawyer your legal issue through the chatbox and it provides you with legal solutions. In a few years’ time robots and AI will be the norm in most sectors. The question is are we ready for robots? AI and robots raise a lot of ethical and moral issues that ought to be considered. The first major issue is the security concerns raised in the use of robots in some industries. The militarisation of AI has been an issue of global concern. In 2019, the UN Office Of Disarmament Affairs had sessions to discuss the peace and security implications of increased use of AI. The UN termed the new emerging technologies in peace and war as the “four horsemen” of modern days. A call has increasingly been made to ban the weaponisation of new technology such as AI. An army of robot soldiers could be disastrous and have an almost “Armageddon” effect. Robot soldiers could be very dangerous and unethical if they fall into the wrong hands. Such robot soldiers could be used to exterminate entire populations based on parameters such as race, gender and age. A second ethical issue that arises in increased usage of AI is rising unemployment. Increased usage will result in job cuts and massive termination. This poses an ethical issue to humanity. What happens if robots begin to take people’s jobs? Robots are better placed in automated tasks because they do not have any physical limitations as human beings. A third ethical issue is the issue of ownership of artificial intelligence, which is important for determining issues such as liability. Who would be liable for the actions/faults/liabilities of robots? For example, if a robot causes harm to someone due to negligence who would be liable? Would it be the owner or the robot itself? The fourth ethical issue that arises is whether robots are natural persons under the law. This is still a grey area and it is not yet clear if a robot would be deemed to be a natural person under the law. In 2017, a robot known as Sophia was granted Saudi Arabian citizenship. This in itself raises many ethical questions. One concern is if Sophia would be subject to Saudi Arabian laws? Other issues would be questions such as when was her date of birth and when is her date of death deemed to be. In the event that robots are considered to be natural persons then the question would be if the law of natural persons applies to them.